1) By default, the root user account password is locked in Ubuntu Linux for security reasons. 

To become a superuser in Linux using sudo command, You must be part of special secondary group on Linux - a sudo group to which a user can be added and then right edited using VISUDO command.

For this reason simply use users with SUDO.

Create user learn4gd to run all crons for site and user marko as a developer user and manticore user for Manticore search engine:

#Create them in the same order on all servers to ensure that same UID is assigned to them:

sudo -s
sudo useradd --create-home learn4gd
sudo useradd --create-home marko
sudo useradd manticore

usermod -a -G sudo marko

#Create password for each user:
passwd marko
passwd learn4gd


#Add learn4gd to sudoers with limited rights:

visudo


#And add the following lines (allows programs view files on server):

learn4gd ALL=NOPASSWD: /backup/scripts/sync_content.sh
learn4gd ALL=NOPASSWD: /usr/bin/rsync
learn4gd ALL=NOPASSWD: /usr/bin/ssh
learn4gd ALL=NOPASSWD: /usr/bin/screen



------------------------
root ALL=(ALL:ALL) ALL

The first field indicates the username that the rule will apply to
(root).

First “ALL” indicates that this rule applies to all hosts.

Second “ALL” indicates that the root user can run commands as all
users.

Third “ALL” indicates that the root user can run commands as all
groups.

Forth “ALL” indicates these rules apply to all commands.
----------------------


As a result, you can not login using root user or use a command such as ‘su -‘ to become a SuperUser.

Type the following command to become root user and issue passwd:

sudo -i passwd root

OR set a password for root user in a single go:

sudo passwd root

Test your root password by typing the following command:

su -

Then execute

sudo passwd -u root 
to unlock the account. This should return

passwd: password expiry information changed


One can disable the root account by typing the following command (for security it is best to leave it locked):
sudo passwd -dl root


2) Add additional 2 disks into RAID 1 and create /backup mount on them

Before you can proceed, ensure that you have mdadm package installed. mdadm is a utility that can be used to manage MD devices aka Linux Software RAID.

#Check if the package is installed.;

apt list -a mdadm

#Check what disks are there:

lsblk

#In order to use a disk as RAID disk, you need to create a RAID partition type on each disk. We have sda and sdb disks:

sudo apt install parted

parted -a optimal /dev/sda mklabel gpt
parted -a optimal /dev/sda mkpart primary ext4 0% 100%
parted -a optimal /dev/sda set 1 raid on
parted -a optimal /dev/sda print

parted -a optimal /dev/sdb mklabel gpt
parted -a optimal /dev/sdb mkpart primary ext4 0% 100%
parted -a optimal /dev/sdb set 1 raid on
parted -a optimal /dev/sdb print

mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/sd[ab]1
mdadm --detail /dev/md0

mdadm --examine /dev/sd[ab]1
mdadm --examine /dev/nvme[01]n1p2
cat /proc/mdstat

mkfs.ext4 /dev/md0

cd /
mkdir /backup
chmod -R 777 /backup
mount /dev/md0 /backup/
df -hT -P /backup/

vim /etc/fstab

#Add the following:
/dev/md0 /backup ext4 defaults 0 0

mdadm --detail --scan >> /etc/mdadm/mdadm.conf
update-initramfs -u

lsblk
lsblk -d -o name && lsblk -d -o serial


mdadm --detail /dev/md0 

If Resync status is 100% complete:
Reboot the server to check if raid loads correctly.


3) Export from /tmp/mc-root/ to TMPDIR=/home/temp to ensure that Midnight commander doesn't fill up the temp dir when logged in as root:


mkdir /home/ubuntu/tmp/
mkdir /home/learn4gd/tmp/
mkdir /home/marko/tmp/

chown marko.marko /home/marko/tmp/
chown learn4gd.learn4gd /home/learn4gd/tmp/
chown ubuntu.ubuntu /home/ubuntu/tmp/

#folder must have 777 permissions otherwise schools, jobs, forums, except main page will go blank.

chmod -R 777 /home/ubuntu/tmp/
chmod -R 777 /tmp/
chmod -R 777 /home/learn4gd/tmp/
chmod -R 777 /home/marko/tmp/


add these lines to the .bashrc for root, ubuntu, learn4gd, marko in bashrc (in each user home) add his corresponding line:

vim /root/.bashrc
MC_TMPDIR=/tmp/
export TMPDIR=/tmp/

vim /home/learn4gd/.bashrc
MC_TMPDIR=/home/learn4gd/tmp/
export TMPDIR=/home/learn4gd/tmp/

vim /home/marko/.bashrc
MC_TMPDIR=/home/marko/tmp/
export TMPDIR=/home/marko/tmp/

vim /home/ubuntu/.bashrc
MC_TMPDIR=/home/ubuntu/tmp/
export TMPDIR=/home/ubuntu/tmp/

chown marko.marko /home/marko/
chown learn4gd.learn4gd /home/learn4gd/
chown ubuntu.ubuntu /home/ubuntu/

sudo mkdir /home/learn4gd/public_html
sudo mkdir /home/learn4gd/public_html/powermedia

chown -R learn4gd.learn4gd /home/learn4gd/public_html


4) Install Midnight commander

First install Universe and additional repository:

sudo add-apt-repository "deb http://archive.ubuntu.com/ubuntu $(lsb_release -sc) main universe restricted multiverse"

sudo apt install mc

F9 OPTIONS and open CONFIGURE OPTIONS, Select 
Use internal edit

and 

OPTIONS->>Confirmation
SELECT

Exit


5) Install or upgrade HTOP

sudo apt install htop

sudo apt upgrade htop

6) Install LOCATE app to be able to use locate xxx_file

sudo apt install mlocate

#Servers need their timezone setup in PHP in order for sessions to work correctly.

#Ubuntu has systemd-timesyncd, check with:

systemctl status systemd-timesyncd

#If not - Install NTP service and synchronize between servers

sudo apt  install chrony
systemctl enable --now chronyd
systemctl status chronyd

#Set proper timezone this server is in Virginia, near New York, check server timezone:

timedatectl

#To view available timezones:
timedatectl list-timezones

#Set timezone:
sudo timedatectl set-timezone America/New_York

8) sudo apt install build-essential gnutls-bin libgnutls28-dev librsync-dev bison flex zip unzip rar unrar

#Install the libblockdev library plugin (and at the same time a standalone library) providing the functionality related to MD RAID

apt install libblockdev-crypto2 libblockdev-mdraid2

9) PCRE must be version 8 or above

sudo apt install libpcre3-dev
pcre-config --version


10) Install Perl logger for better logging of Cpan - answer yes, on first question

sudo cpan install Text::CSV_XS
sudo cpan install SQL::Statement
sudo cpan install DBI
sudo cpan install DBD::File

sudo cpan install Log::Log4perl

11) Install JSON serializer

sudo cpan install  JSON::XS

12) Add local IP addresses to both local NICs of each server:

# See what network interfaces are setup:
ls /etc/netplan
cd /etc/netplan

#Check what other interfaces available and setup local IP address:
ip a

#CheckEthernet card settings
sudo ethtool ens13f0

#Do not use this as they would setup temporary (until reboot) and currently secondary network card is not used
#sudo ip link set dev ens13f0 up
#sudo ip link set dev ens13f1 up
#sudo ip address add 10.10.10.1/27 dev ens13f0
#sudo ip address add 10.10.10.2/27 dev ens13f1

vim /etc/netplan/99_config.yaml
#Enter the following:

# One local network card configured manually
network:
    version: 2
    ethernets:
        ens13f0:
            addresses:
                    - 10.10.10.1/27


sudo netplan try
sudo netplan apply
ip a


13) SSH port should be set to listen on port 2056

sudo vim /etc/ssh/sshd_config

#enter
Port 2056

#After change of standard 22 port to 2056 port, restart ssh service:

systemctl restart sshd


14) Enable firewall (while on KVM as otherwise may get disconnected from SSH):

First, ufw needs to be enabled. From a terminal prompt enter:

sudo ufw enable

sudo ufw status verbose

#First list the rules which would always be allowed

sudo ufw allow proto tcp from any to any port 80,443
sudo ufw allow from 10.10.10.0/27
sudo ufw allow 53
#these just for Email server:
sudo ufw allow 25,587


#OVH monitoring ports and IPs - allow inbound and outbound connections on UDP ports 6100 through 6200 and ICMP

sudo ufw allow from 147.135.0.20
sudo ufw allow from 147.135.33.68
sudo ufw allow from 147.135.0.224/28
sudo ufw allow from 37.187.231.251
sudo ufw allow from 151.80.231.244
sudo ufw allow from 151.80.231.245
sudo ufw allow from 151.80.231.246
sudo ufw allow from 151.80.231.247
sudo ufw allow from 213.186.33.62
sudo ufw allow from 92.222.184.0/24
sudo ufw allow from 92.222.185.0/24
sudo ufw allow from 92.222.186.0/24
sudo ufw allow from 167.114.37.0/24
sudo ufw allow from 213.186.45.4
sudo ufw allow from 213.251.184.9
sudo ufw allow from 37.59.0.235
sudo ufw allow from 8.33.137.2
sudo ufw allow from 213.186.33.13
sudo ufw allow from 213.186.50.98
sudo ufw allow from 51.81.92.18
sudo ufw allow from 147.135.33.106

#Last 2 IPs are per server IP. Server IP last number replaced by .250 and 251 as explained on https://support.us.ovhcloud.com/hc/en-us/articles/115001821044-Overview-of-OVHcloud-Monitoring

sudo ufw allow from 135.148.35.250
sudo ufw allow from 135.148.35.251

#Add these temporarily for old servers to allow pushing/pulling files and allow git access
#Allow rules must come before the deny rules (like country deny) , otherwise they are rejected. Alternative - remove country rule and add it again
sudo ufw allow from 67.227.189.210
sudo ufw allow from 67.225.255.238
sudo ufw allow from 67.227.192.101
sudo ufw allow from 67.225.163.22


sudo ufw status verbose
sudo ufw status numbered

#Limit access to certain ports by country:

sudo apt install xtables-addons-common
mkdir /usr/share/xt_geoip
cd /usr/share/xt_geoip
sudo apt install libtext-csv-xs-perl unzip
/usr/lib/xtables-addons/xt_geoip_dl
chmod 755 /usr/lib/xtables-addons/xt_geoip_build

#A space is needed before * as it reads whole directory that way
/usr/lib/xtables-addons/xt_geoip_build -D /usr/share/xt_geoip *.csv


#On all servers
iptables -A INPUT -m geoip --src-cc RS,LT,GB,IE -p TCP --dport 2056 -j ACCEPT
iptables -A INPUT -m geoip --src-cc RS,LT,GB,IE -p TCP --dport 8443 -j ACCEPT

#Only for VPN server
iptables -A INPUT -m geoip --src-cc RS,LT,GB,IE -p UDP --dport 12912 -j ACCEPT


#On email server only
iptables -A INPUT -m geoip --src-cc LT,GB,IE -p TCP --dport 465 -j ACCEPT
#Do not add such as this is SUBMISSIONS port which is sometimes used to deliver emails (called Submission - while old deprecated 465 port is called Submissions)
#Also - old or other servers send mail via this port and since they are US based - would be blocked
####iptables -A INPUT -m geoip --src-cc LT,GB,IE -p TCP --dport 587 -j ACCEPT
iptables -A INPUT -m geoip --src-cc LT,GB,IE -p TCP --dport 995 -j ACCEPT


#Install iptables persistence to retain rules after restarts

sudo apt install iptables-persistent

#It will offer to save current rules to /etc/iptables/rules.v4 to load each time after reboot
#Choose yes

#After adding new rules - save them every time so they are loaded each time on server reboot:

#Any time you modify your rules, run 

sudo netfilter-persistent save

#And then 

sudo netfilter-persistent reload

#Which saves separately v4 and v6 rules and no need to run commands like:
#/sbin/iptables-save > /etc/iptables/rules
#iptables-restore < /etc/iptables/rules
#or 
#iptables-save -f /etc/iptables/rules.v4 (for iptables)
#iptables-save -f /etc/iptables/rules.v6 (for ip6tables)



#Add to service file loading of iptables rules and saving on system shutdown/reboot in case it was forgotten to save manually:

vim /etc/systemd/system/load-iptables-rules.service


[Unit]
Description=Load iptables rules after network is available and save them on shutdown
Wants=network-online.target
After=network-online.target

[Service]
Type=oneshot
RemainAfterExit=true
User=root
ExecStart=netfilter-persistent reload
ExecStop=netfilter-persistent save

[Install]
WantedBy=multi-user.target

#Enable service

systemctl enable load-iptables-rules
systemctl start load-iptables-rules
systemctl status load-iptables-rules

#Reboot server to test rules are restored


#https://www.rsyslog.com/doc/v8-stable/configuration/filters.html
#Direct all UFW and iptables log messages into separate log file:

vim /etc/rsyslog.d/20-ufw.conf

#This will make it go to this one file
:msg,contains,"[UFW " /var/log/ufw.log


#Uncomment this line to prevent additional logging into /var/log/kern.log

& stop


#Restart rsyslog

sudo service rsyslog restart



##Split mail log, daemon and cron files and log only in them , without duplicating in syslog file

##*.* selects messages from all facilities (auth, authpriv, cron, daemon, kern, lpr, mail, mark, news, security (same as auth), syslog, user, uucp and local0 through local7), with all priorities (debug, info, notice, warning, warn (same as warning), err, error (same as err), crit, alert, emerg, panic (same as emerg))

##; starts a new selector

##auth,authpriv,mail.none selects auth, authpriv and mail facilities with no priority (meaning it selects none of the messages because all messages have a priority). This selector overrides the *.* selector for those particular facilities.



vim /etc/rsyslog.d/50-default.conf

#Uncomment these

# First some standard log files.  Log by facility.
#
auth,authpriv.*                 /var/log/auth.log
*.*;auth,authpriv,mail.none    -/var/log/syslog
cron.*                          /var/log/cron.log
daemon.*                        -/var/log/daemon.log
kern.*                          -/var/log/kern.log
#lpr.*                          -/var/log/lpr.log
mail.debug;mail.!err            -/var/log/mail.log
user.*                          -/var/log/user.log

#
# Logging for the mail system.  Split it up so that
# it is easy to write scripts to parse these files.
#
mail.info                       -/var/log/mail.info
mail.warn                       -/var/log/mail.warn
mail.err                        /var/log/mail.err




sudo service rsyslog restart



##########################################################################
#Not needed as default policy is to drop incomming external
#iptables -A INPUT -p 12912 -j DROP

#Check list of rules added for incomming traffic:

iptables -L INPUT

#Get the list of rules in numberred list:

iptables -L INPUT --line-numbers

#Replace rule 7 and 8

iptables -R INPUT 8 -m geoip --src-cc RS,LT,GB,IE -p UDP --dport 12912 -j ACCEPT

iptables -R INPUT 7 -m geoip --src-cc RS,LT,GB,IE -p TCP --dport 2056 -j ACCEPT

#Delete incomming traffic rule number 11

iptables -D INPUT 11

Default policy:

Default: deny (incoming), allow (outgoing), deny (routed)


####Enable Monitoring of Specific Services
In addition to the standard Monitoring, you can enable OVHcloud to monitor specific services such as HTTP, SSH, and other protocols in the OVHcloud Manager. To do this, click Monitor my services under the "Service status" section on the Server status tab. Click Monitor a service and add port 2056 to SSH.

----------------------------------------------------


Examples of use:

#To remove to rule

#sudo ufw delete allow 2056

#Similarly, to close an opened port (on current setup is enough to remove from allowed ports):

#sudo ufw deny 22

#To remove a rule, use delete followed by the rule:

#sudo ufw delete deny 22

# To view list of rules

sudo ufw status numbered

#And default status:
sudo ufw status verbose

#It is also possible to allow access from specific hosts or networks to a port. The following example allows SSH access from host 192.168.0.2 to any IP address on this host:

#sudo ufw allow proto tcp from 192.168.0.2 to any port

#Replace 192.168.0.2 with 192.168.0.0/24 to allow SSH access from the entire subnet.

#Adding the –dry-run option to a ufw command will output the resulting rules, but not apply them. For example, the following is what would be applied if opening the HTTP port:

#sudo ufw --dry-run allow http


ufw Application Integration
Applications that open ports can include an ufw profile, which details the ports needed for the application to function properly. The profiles are kept in /etc/ufw/applications.d, and can be edited if the default ports have been changed.

To view which applications have installed a profile, enter the following in a terminal:

sudo ufw app list
Similar to allowing traffic to a port, using an application profile is accomplished by entering:

sudo ufw allow Samba
An extended syntax is available as well:

sudo ufw allow from 192.168.0.0/24 to any app Samba

==================================================================================================

==========================================
#Saving IPtables rules permanently method 2:


 There are two files (one if your system is not IPv6) that need to be edited:

/etc/ufw/before.rules
/etc/ufw/before6.rules

As the naming suggests, the before6.rules file is for IPv6 and before.rules is for IPv4. Adding rules to these files is easy. Just add it before the COMMIT statement at the end of the file. An example of the ACCEPT rule above, add this like to the file(s):

-A ufw-before-input -m geoip --src-cc RS,LT,GB,IE -p TCP --dport 2056 -j ACCEPT

=============================================
#Merge several protocols into one rule:

Create a new chain which will accept any TCP and UDP packets, and jump to that chain from the individual IP/port permissive rules:

iptables -N ACCEPT_TCP_UDP iptables -A ACCEPT_TCP_UDP -p tcp -j ACCEPT

iptables -A ACCEPT_TCP_UDP -p udp -j ACCEPT

iptables -A zone_lan_forward -d 1.2.3.0/24 -j ACCEPT_TCP_UDP

This adds the overhead of a few extra lines, but halves the number of TCP / UDP rules.


============================================================================
#To trace the packet flow when traffic is blocked - add the rule - with port or with specific IP (which is being blocked) and see which rules affect it:

iptables -t raw -A PREROUTING -p tcp --dport 8444 -j TRACE
iptables -t raw -A PREROUTING -s 88.118.160.124 -p tcp --dport 8444 -j TRACE

#View the log (as they are sent by default to syslog and not UFW log):

cat /var/log/syslog | grep TRACE:

#View the rules:
iptables -t raw -v -L PREROUTING -n --line-number

#Delete the rule from table raw  PREROUTING  chain when that rule is number 1 for example:
iptables -t raw -D PREROUTING 1

#Method 2 to trace blocked traffic:


    Create an identical rule but one whose target is LOG rather than ACCEPT or DROP etc. That rule comes before the one you want to test. -I inserts it as rule #1 by default


    iptables -I INPUT -s 88.118.160.124 -p tcp --dport 8444 -j LOG --log-level info 

    or just port

    iptables -I INPUT  -p tcp --dport 8444 -j LOG --log-level info

    You can find the log output where you have kernel logs directed to.

    #View the log (as they are sent by default to syslog and not UFW log):
    cat /var/log/syslog


    After the rule is in place try to reach the tested port, run iptables with -v and -x options to see the exact counts of packets that have hit each rule. I use:

    iptables -L INPUT -nvx

    Let's say the rule is #6 in the list. You can monitor just that one using the handy watch program:

    watch -n 0.5 iptables -L INPUT 6 -nvx

    which will update the display every 1/2 second.


#View your rule (since Insert by default inserts new rules as rule 1 - this rule will be rule #1

iptables -v -L INPUT -n --line-number

#Delete the rule after finished monitoring
iptables -D INPUT 1



---------------------------------------------------------

15) #On New Ubuntu server add (root is not permitted to log in):

vim /root/.ssh/config

host 10.10.10.1
  User root
  port 2056

host 10.10.10.3
  User root
  port 2056

host 10.10.10.5
  User root
  port 2056

host 10.10.10.7
  User root
  port 2056

host 10.10.10.9
  User root
  port 2056

Create such file to Ubuntu, learn4gd and Marko users:

mkdir /home/marko/.ssh
mkdir /home/ubuntu/.ssh
mkdir /home/learn4gd/.ssh


touch /home/marko/.ssh/config
touch /home/ubuntu/.ssh/config
touch /home/learn4gd/.ssh/config

chown -R marko.marko /home/marko/.ssh
chown -R ubuntu.ubuntu /home/ubuntu/.ssh
chown -R learn4gd.learn4gd /home/learn4gd/.ssh

chown marko.marko /home/marko/.ssh/config
chown ubuntu.ubuntu /home/ubuntu/.ssh/config
chown learn4gd.learn4gd /home/learn4gd/.ssh/config

#Change host user to own user 

vim /home/marko/.ssh/config

host 10.10.10.1
  User marko
  port 2056

host 10.10.10.3
  User marko
  port 2056

host 10.10.10.5
  User marko
  port 2056

host 10.10.10.7
  User marko
  port 2056

host 10.10.10.9
  User marko
  port 2056



vim /home/ubuntu/.ssh/config


host 10.10.10.1
  User ubuntu
  port 2056

host 10.10.10.3
  User ubuntu
  port 2056

host 10.10.10.5
  User ubuntu
  port 2056

host 10.10.10.7
  User ubuntu
  port 2056

host 10.10.10.9
  User ubuntu
  port 2056



vim /home/learn4gd/.ssh/config

host 10.10.10.1
  User learn4gd
  port 2056

host 10.10.10.3
  User learn4gd
  port 2056

host 10.10.10.5
  User learn4gd
  port 2056

host 10.10.10.7
  User learn4gd
  port 2056

host 10.10.10.9
  User learn4gd
  port 2056


#Add each host to vRack to make sure they are on the same local network and can see each other before setting up access between them

Setup SSH keys:

Setup passwordless SSH between all servers - setup SSH keys between the machines  so script can connect between them without asking for root password and fingerprint.
Visit each server from each other to add to known hosts once keys have been setup on each server
On each server do this:
#####ssh-keygen -t rsa #######Older algorithm
ssh-keygen -t ed25519
exit

#Then for all other users:
sudo -u marko -s
ssh-keygen -t ed25519
exit

sudo -u learn4gd -s
ssh-keygen -t ed25519
exit

#Stay as Ubuntu user
ssh-keygen -t ed25519

On each server do the other server(s) IP SSH - do not do OWN key to itself:

On all the other servers do:

vim /root/.ssh/authorized_keys

#Copy the output of this command for root user from current server:
sudo -s
cat /root/.ssh/id_ed25519.pub

#And paste the key copied from cat command for each key  from each server

#Such transfer of keys has to be done different for root user since it is not permitted to login and other user does not have access to its files thus each server must be logged in separately and then its commands executed:


#Repeat the above in opposite direction with another server. Each server pair must be done individually in both directions

Once root user is done on both side for all server do in shell by each IP for other users (do not do OWN IP):

sudo -s

#Do the first line separately as answer YES is needed for the first connection

ssh root@10.10.10.3 "cat >> /home/ubuntu/.ssh/authorized_keys" < /home/ubuntu/.ssh/id_ed25519.pub
ssh root@10.10.10.3 "cat >> /home/marko/.ssh/authorized_keys" < /home/marko/.ssh/id_ed25519.pub
ssh root@10.10.10.3 "cat >> /home/learn4gd/.ssh/authorized_keys" < /home/learn4gd/.ssh/id_ed25519.pub

ssh root@10.10.10.5 "cat >> /home/ubuntu/.ssh/authorized_keys" < /home/ubuntu/.ssh/id_ed25519.pub
ssh root@10.10.10.5 "cat >> /home/marko/.ssh/authorized_keys" < /home/marko/.ssh/id_ed25519.pub
ssh root@10.10.10.5 "cat >> /home/learn4gd/.ssh/authorized_keys" < /home/learn4gd/.ssh/id_ed25519.pub

ssh root@10.10.10.7 "cat >> /home/ubuntu/.ssh/authorized_keys" < /home/ubuntu/.ssh/id_ed25519.pub
ssh root@10.10.10.7 "cat >> /home/learn4gd/.ssh/authorized_keys" < /home/learn4gd/.ssh/id_ed25519.pub
ssh root@10.10.10.7 "cat >> /home/marko/.ssh/authorized_keys" < /home/marko/.ssh/id_ed25519.pub

ssh root@10.10.10.9 "cat >> /home/ubuntu/.ssh/authorized_keys" < /home/ubuntu/.ssh/id_ed25519.pub
ssh root@10.10.10.9 "cat >> /home/learn4gd/.ssh/authorized_keys" < /home/learn4gd/.ssh/id_ed25519.pub
ssh root@10.10.10.9 "cat >> /home/marko/.ssh/authorized_keys" < /home/marko/.ssh/id_ed25519.pub


16) You can make autogenerated answers file to make installation more automated (we have one script made and we are using thus autoexpect allows executing it):
To make an autogenerated answer script use this as an example:

#autoexpect sudo -u learn4gd git pull --rebase

Type in all answers and it it generates script.exp file which is executable file then and answers prompts which then can be run as any other shell scripts


sudo apt install expect

17)  Install Aspell

sudo apt install aspell aspell-en aspell-de aspell-es aspell-nl aspell-fr libtext-aspell-perl -y

sudo cpan install Text::Aspell

18) Install pigz
sudo apt install pigz

19) Install Nload
sudo apt install nload

20) Setup FTP server
sudo apt update
sudo apt install vsftpd
sudo systemctl status vsftpd
vim /etc/vsftpd.conf

#Have these settings:
anonymous_enable=NO
local_enable=YES
write_enable=YES
local_umask=022
chroot_local_user=YES

sudo systemctl restart vsftpd

Connect to FTP server using SFTP port 2056


21) Install MariaDB

sudo apt install curl libcurl4-gnutls-dev software-properties-common dirmngr
sudo apt-key adv --fetch-keys 'https://mariadb.org/mariadb_release_signing_key.asc'

#Next, run the command in your terminal to import the MariaDB 10.6 repository:

sudo add-apt-repository 'deb [arch=amd64,arm64,ppc64el] https://mariadb.mirror.liquidtelecom.com/repo/10.6/ubuntu focal main'
sudo apt update

sudo apt install mariadb-server mariadb-client libmysqlclient-dev

mariadb --version
systemctl status mariadb

Configure MariaDB:

cd /etc/mysql/mariadb.conf.d/
mv 50-server.cnf server.cnf
vim /etc/mysql/mariadb.conf.d/server.cnf
#Comment out this line so MariaDB listens on all IPs
#bind-address = 127.0.0.1

FOR WEB1 SERVER CONFIG USE JUST THESE LINES continue editing vim /etc/mysql/mariadb.conf.d/server.cnf :

---------------------------------------------------
[mysqld]

#
# * Basic Settings
#

user                    = mysql
pid-file                = /run/mysqld/mysqld.pid
basedir                 = /usr
datadir                 = /var/lib/mysql
lc-messages-dir         = /usr/share/mysql
lc-messages             = en_US
skip-external-locking

#Replication Settings
log-bin
server_id=11
expire_logs_days=3

gtid_domain_id=11
log-basename=master11
binlog_format=mixed

replicate_do_db=learn4gd_cms
replicate_do_db=learn4gd_schools2

performance-schema=0
sql_mode="STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION"
open_files_limit = 65535
log-error=/var/lib/mysql/errors.log
tmpdir = /var/lib/mysql/tmp
default-storage-engine=InnoDB
innodb_file_per_table=1
innodb_defragment=1
innodb_flush_method=O_DIRECT
innodb_buffer_pool_size=8G
innodb_log_file_size=128M
innodb_log_buffer_size =64M
innodb_io_capacity = 200
innodb_read_io_threads = 64
innodb_write_io_threads = 64
max_connections=400
key_buffer_size = 10M
max_allowed_packet=512M
#slow_query_log= 1
#slow_query_log_file= /var/lib/mysql/slow.log
#long_query_time= 1
#log_queries_not_using_indexes=1
wait_timeout=120
interactive_timeout=120
innodb_lock_wait_timeout=60
lock_wait_timeout = 50
read_buffer_size = 128K
table_definition_cache = 1400
max_heap_table_size = 128M
tmp_table_size = 128M
join_buffer_size = 256K
sort_buffer_size = 256K

skip-name-resolve=1
query_cache_type = 0
query_cache_size = 0
innodb_buffer_pool_dump_pct=75
innodb_buffer_pool_dump_at_shutdown=ON
innodb_buffer_pool_load_at_startup=ON
sync_binlog=0

[mysqldump]
max_allowed_packet=512M

#Comment OUT THESE LINES

#expire_logs_days        = 10
#character-set-server  = utf8mb4
#collation-server      = utf8mb4_general_ci


-------------------------------------------------------------------------



22)  Create all users on all databases


----------------------------------------------------------

23)  Important as Manticore and MySQL will crash if it creates 1024 files (default open files setting for all users) and opens them - number of Open files limit needs to be increased on the systems:

#Check them (Show what MariaDB wants):

sudo mysql -e 'show variables like "open_files_limit";'

#Shows what is allowed by the system:

su mysql bash -c "ulimit -Sn"

su learn4gd bash -c "ulimit -Sn"


It should be no less than 65535


“/etc/sysctl.conf” file is used to set resource limit system wide but if you want to set resource limit for specific user like MariaDB and Apache then this can be achieved via “/etc/security/limits.conf” file.

vim /etc/security/limits.conf

#Add the following


ubuntu          soft    nofile          245000
ubuntu          hard    nofile          250000
root          soft    nofile          245000
root          hard    nofile          250000
root          soft    core          unlimited
manticore          soft    nofile          50000
manticore          hard    nofile          65000
manticore       -       memlock         unlimited
manticore          soft    core          unlimited
learn4gd          soft    nofile          250000
learn4gd          hard    nofile          255000
mysql          soft    nofile          145000
mysql          hard    nofile          150000


reboot server

sudo -s

su learn4gd bash -c "ulimit -Sn"


vim /lib/systemd/system/mariadb.service

#Edit the line near the botom to have
LimitNOFILE=65535

sudo systemctl daemon-reload
systemctl restart mariadb
systemctl status mariadb

sudo mysql -e 'show variables like "open_files_limit";'



------------------------------------------------------------------------------------------------------------
This shows the total files can be open system wide
cat /proc/sys/fs/file-max

ulimit
shows all limits for the user which is logged in , it is not possible to check limits for users with no login password like MySQL


To display the individual resource limit then pass the individual parameter in ulimit command, some of parameters are listed below:

The mappings of systemd limits to ulimit

Directive        ulimit equivalent     Unit
LimitCPU=        ulimit -t             Seconds      
LimitFSIZE=      ulimit -f             Bytes
LimitDATA=       ulimit -d             Bytes
LimitSTACK=      ulimit -s             Bytes
LimitCORE=       ulimit -c             Bytes
LimitRSS=        ulimit -m             Bytes
LimitNOFILE=     ulimit -n             Number of File Descriptors 
LimitAS=         ulimit -v             Bytes
LimitNPROC=      ulimit -u             Number of Processes 
LimitMEMLOCK=    ulimit -l             Bytes
LimitLOCKS=      ulimit -x             Number of Locks 
LimitSIGPENDING= ulimit -i             Number of Queued Signals 
LimitMSGQUEUE=   ulimit -q             Bytes
LimitNICE=       ulimit -e             Nice Level 
LimitRTPRIO=     ulimit -r             Realtime Priority  
LimitRTTIME=     No equivalent
If a ulimit is set to 'unlimited' set it to 'infinity' in the systemd config

ulimit -c unlimited is the same as LimitCORE=infinity
ulimit -v unlimited is the same as LimitAS=infinity
ulimit -m unlimited is the same as LimitRSS=infinity


Use below commands check hard and soft limits for number of open file for the logged in user

ulimit -Hn
ulimit -Sn

Use sysctl command to pass fs.file-max parameter to kernel on the fly, execute beneath command as root user,

sysctl -w fs.file-max=12326274

Above changes will be active until the next reboot, so to make these changes persistent across the reboot, edit the file /etc/sysctl.conf and add same parameter

vi /etc/sysctl.conf
fs.file-max=12326274

Run the beneath command to make above changes into effect immediately without logout and reboot.

sysctl -p

cat /proc/sys/fs/file-max

Use below command to find out how many file descriptors are currently being utilized:

more /proc/sys/fs/file-nr

-----------------------------------------------------------------------

24) /etc/hosts file - enter all hosts needed on our network

vim /etc/hosts

127.0.1.1       web1     web1
10.10.10.1      web1.learn4good.com web1
135.148.35.89  web1.learn4good.com web1
10.10.10.3      web2.learn4good.com web2
135.148.35.88  web2.learn4good.com web2
10.10.10.5      email.learn4good.com email
135.148.35.38   email.learn4good.com email
10.10.10.7      bdb.learn4good.com bdb
135.148.35.73   bdb.learn4good.com bdb
10.10.10.9      redis.learn4good.com redis
135.148.35.94  redis.learn4good.com redis


vim /etc/hostname
#Add
web1.learn4good.com


25) Install Apache with PHP

sudo apt install net-tools autoconf
sudo apt install libfcgi-dev libfcgi0ldbl libjpeg-turbo8-dev libmcrypt-dev libssl-dev libc-client-dev libxml2 libxml2-dev libbz2-dev mcrypt
sudo apt install libjpeg-dev libpng-dev libfreetype6-dev libkrb5-dev libpq-dev libxslt1-dev libzip-dev libsqlite3-dev libonig-dev mutt lftp dos2unix libpcap-dev lft libmemcached-dev libevent-dev sasl2-bin libsasl2-dev libfuzzy-dev 


sudo apt install apache2
sudo apt install libapache2-mod-fcgid libapache2-mod-xsendfile

sudo apt install gcc make pkg-config php-pear php-dev libapache2-mod-perl2

#Prevent PECL errors 
mkdir -p /tmp/pear/cache
chmod -R 777 /tmp/pear/

pear channel-update pear.php.net
pear install Archive_Tar

sudo apt install php7.4-fpm php7.4-opcache php7.4-readline libzip5 zlib1g zlib1g-dev php-igbinary

sudo apt install php-common php7.4-cli php7.4-common php7.4-curl php7.4-gd php7.4-json php7.4-mbstring php7.4-mysql php7.4-xml

sudo apt install php7.4-bcmath php7.4-bz2 php7.4-dba php7.4-dev php-msgpack php-readline php-mysqlnd

sudo apt install php7.4-fileinfo php7.4-ftp php7.4-gettext php7.4-gmp php7.4-iconv php7.4-imap php7.4-intl php-memcached

sudo apt install php7.4-pspell php7.4-soap php7.4-tidy php7.4-xmlrpc php7.4-zip




a2dismod mpm_prefork mpm_worker
sudo a2enmod asis deflate env expires fcgid headers mime_magic mpm_event proxy proxy_fcgi proxy_http proxy_wstunnel remoteip slotmem_plain ssl unique_id actions alias http2 rewrite perl xsendfile

To enable PHP 7.4 FPM in Apache2 do:
sudo a2enmod proxy_fcgi setenvif
sudo a2enconf php7.4-fpm


vim /etc/apache2/conf-available/security.conf

#Change/Set the following:

ServerTokens Prod
ServerSignature Off

pecl channel-update pecl.php.net
sudo pecl install zip
phpenmod zip



pecl install mcrypt

vim  /etc/php/7.4/mods-available/mcrypt.ini
extension=mcrypt.so

phpenmod mcrypt

pecl install timezonedb

vim  /etc/php/7.4/mods-available/timezonedb.ini
extension=timezonedb.so

phpenmod timezonedb


#msgpack seem to have its module enabled in PHP ini files, if not - install

sudo pecl install msgpack
#Add to ini files
phpenmod msgpack



##COPY from EMAIL server /etc/apache2/conf-enabled/ dirs,cf-list and sites folders, they are Rewrite rules holders for the website

mkdir /etc/apache2/conf-enabled/dirs
mkdir /etc/apache2/conf-enabled/cf-list
mkdir /etc/apache2/conf-enabled/sites

scp  ubuntu@10.10.10.5:/etc/apache2/conf-enabled/dirs/*.* /etc/apache2/conf-enabled/dirs/
scp  ubuntu@10.10.10.5:/etc/apache2/conf-enabled/cf-list/*.* /etc/apache2/conf-enabled/cf-list/
scp  ubuntu@10.10.10.5:/etc/apache2/conf-enabled/sites/*.* /etc/apache2/conf-enabled/sites/

#copy everything from   /var/www/html/  to  /var/www/html/

scp -r ubuntu@10.10.10.5:/var/www/html /var/www


#Rename unnecessary config:

mv /etc/apache2/sites-available/default-ssl.conf /etc/apache2/sites-available/default-ssl.conf.unused


#Since all servers have identical configuration we can simply copy the main config files from Email server to other servers, add learn4good subdomains and main domain certificates to config files and uncomment them
#We have to edit the files on email server first to include subdomains certificates.

#From email server copy main config files to each server:

scp  ubuntu@10.10.10.5:/etc/apache2/sites-available/*.* /etc/apache2/sites-available/


#PHP FPM 
# PHP FPM loading from he last lines of  /etc/php/7.4/fpm/php-fpm.conf and /etc/php/7.4/fpm/php.ini


vim /etc/apache2/envvars

#Edit user under which Apache runs. It must run under learn4gd instead of www-data
#instead of www-data user by copying prepared file from Email server

scp  ubuntu@10.10.10.5:/etc/apache2/envvars /etc/apache2/
scp  ubuntu@10.10.10.5:/etc/apache2/apache2.conf /etc/apache2/


#Create FPM log folder:
mkdir /var/log/apache2/fpm/
chmod 777 /var/log/apache2/fpm/

#Copy default pool file and create separate profile for main domain
cd /etc/php/7.4/fpm/pool.d/
cp www.conf l4g.conf
mv www.conf www.conf.bak


#Copy PHP FPM pool files from Email server

scp  ubuntu@10.10.10.5:/etc/php/7.4/fpm/pool.d/*.* /etc/php/7.4/fpm/pool.d/



#CLI PHP settings copy from Email server

scp  ubuntu@10.10.10.5:/etc/php/7.4/cli/php.ini /etc/php/7.4/cli/


####PHP FPM settings
vim /etc/php/7.4/fpm/php.ini

scp  ubuntu@10.10.10.5:/etc/php/7.4/fpm/php.ini /etc/php/7.4/fpm/


#Proxy IPs to exclude by mod_remoteip and return real visitor IP
#Files Were copied earlied from Email server to /etc/apache2/conf-enabled/cf-list/cf-ip4.lst and /etc/apache2/conf-enabled/cf-list/cf-ip6.lst
#mkdir /etc/apache2/conf-enabled/cf-list


Certificates need renewal every 3 months. Will leave redirecting domains as commented out and serve everything to cloudflare on port 80 for them as they do not need SSL certificate. 
These domains do not need certificates: 

www.learn4good.ie www.learnforgood.net www.learn4good.eu www.learn4good.info www.learnforgood.co.uk www.learnforgood.org

--------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------
#Generate free certificate from Lets Encrypt on Email server having pointing all additional domains to one IP. A copy to other servers is not needed as they would not serve those additional domains. Email will be renewing Additional domains, its own and 2 main domain certificates (which are copied to other servers). Each other server will generate just its own certificate.

#Virtualhosts being added to the SSL for the first time (when no SSL certificate file is present on the server) should not be on port 443 (change to 440 temporary) as an error will tell that you are serving port 80 on standart SSL port

#Install LetsEncrypt service. Later for renewals need to run just: sudo certbot certonly --apache . Except for redirecting domains. Below is the list of needed domains only


#Install on each server.

sudo snap install core; sudo snap refresh core

sudo snap install --classic certbot

sudo ln -s /snap/bin/certbot /usr/bin/certbot

#Start from pointing Redis server DNS to new server and making rDNS for it as well
#Copy certificates from email server
#SCP does not have permission to read under Ubuntu user, use MC to copy files to each server

#create folder on each server:
#Run this command on each server to get letsencrypt folder created, nevermind if it fails to talk to Apache as it has no SSL certificates and port 80 disabled

sudo certbot certonly -d web1.learn4good.com --apache

#Copy /etc/letsencrypt/live and  /etc/letsencrypt/archive folders from Email server to the other servers to allow Apache startup without SSL errors. Use Midnight Commander for this as SCP will not copy

#Restart Apache on each server

systemctl restart php7.4-fpm
systemctl restart apache2

#Point DNS at this server during period of certificate generation:
#Now get the certificate on each server its own

sudo certbot certonly -d web1.learn4good.com --apache

#Enter your email address if asked as certificate is server wide
#Generate certificate for each domain and each subdomain separately

#Use these certificates in Apache subdomain Vhosts
#Certificate is saved at: /etc/letsencrypt/live/web1.learn4good.com/fullchain.pem
#Key is saved at:         /etc/letsencrypt/live/web1.learn4good.com/privkey.pem

#Check certificates server sees as own (the Archive and live folders are for email and Apache to use as certificate sources but certbot has own registry of which certificates it is responsible)

sudo certbot certificates

#Start the cron job for letsecrypt

#Check if renewal is enabled:
sudo certbot renew --dry-run

#Delete unnecessary certificate which gives a list of certificates available

sudo certbot delete

#To get a list of certificates:

sudo certbot certificates

The command to renew certbot is installed in one of the following location:


systemctl list-timers

----------------------------------------------------------------------------------------
#Create Vhost for each subdomain in /etc/apache2/conf-enabled/sites/l4g-subdomains.conf on Email server and copy to all servers
#Add SSL certificate for each subdomain individually

#execute on all servers:

chown -R learn4gd.learn4gd /var/www/html

#Enable all subdomains in:

vim /etc/apache2/conf-enabled/sites/l4g-subdomains.conf

#Then, using Midnight Commander copy other servers subdomain certificates -archive and live folder from letsencrypt to Email server. This allows the simplicity of using one subdomains include file, which holds all subdomains, to be used on all servers.

#Then copy  to all servers the certificates of other servers, so each server has certificate files of other servers.

#Continue with PHP FPM settings below as subdomains will not work yet






systemctl restart php7.4-fpm
systemctl restart apache2
----------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------

#Review PHP FPM service on Ubuntu
vim /lib/systemd/system/php7.4-fpm.service

Make sure the helper has default FPM pool is mentioned in service file:

[Unit]
Description=The PHP 7.4 FastCGI Process Manager
Documentation=man:php-fpm7.4(8)
After=network.target

[Service]
Type=notify
ExecStart=/usr/sbin/php-fpm7.4 --nodaemonize --fpm-config /etc/php/7.4/fpm/php-fpm.conf
ExecStartPost=-/usr/lib/php/php-fpm-socket-helper install /run/php/php-fpm.sock /etc/php/7.4/fpm/pool.d/l4g.conf 74
ExecStopPost=-/usr/lib/php/php-fpm-socket-helper remove /run/php/php-fpm.sock /etc/php/7.4/fpm/pool.d/l4g.conf 74
ExecReload=/bin/kill -USR2 $MAINPID

[Install]
WantedBy=multi-user.target



systemctl daemon-reload


#PHP FPM Emergency restart

vim /etc/php/7.4/fpm/php-fpm.conf

#Set these lines to the following values:

emergency_restart_threshold= 3
emergency_restart_interval= 1m
process_control_timeout= 5s

error_log = /var/log/apache2/fpm/php7.4-fpm.log

#Restart PHP FPM and Apache

systemctl restart php7.4-fpm
systemctl restart apache2


Copy certificates from old server for learn4good.com
Copy certificates for other domains from lets encrypt - /etc/letsencrypt/
Copy config files from /etc/apache2 and /etc/php/ to other servers.

#Check certificate validity with https://www.digicert.com/help/

sudo apachectl configtest
systemctl restart php7.4-fpm
systemctl restart apache2
sudo apachectl -M
sudo systemctl status php7.4-fpm
sudo systemctl status apache2

#Check listening ports:

sudo lsof -i :8443
sudo lsof -i :443
sudo lsof -i :80



##Check if all PHP extensions are loaded in ini files:

php --ini

##On production use (which does not reload configuration just restarts the process)

sudo systemctl reload apache2

#To enable site in sites-available folder use

#a2ensite site_config_file_name.conf

#systemctl restart apache2
-------------------------------------

#Copy Opcache settings to ini file
scp  ubuntu@10.10.10.5:/etc/php/7.4/mods-available/opcache.ini /etc/php/7.4/mods-available/
 

#Create Opcache blacklist file - GEOIP seem to be moved to COMMON/VENDORS and does not use PHAR file anymore
#Skip this

vim /etc/php/7.4/mods-available/opcache.blacklist

#Add this into it

; The blacklist file is a text file that holds the names of files
; that should not be accelerated. The file format is to add each filename
; to a new line. The filename may be a full path or just a file prefix
; (i.e., /var/www/x  blacklists all the files and directories in /var/www
; that start with 'x'). Line starting with a ; are ignored (comments).
; Files are usually triggered by one of the following three reasons:
; 1) Directories that contain auto generated code, like Smarty or ZFW cache.
; 2) Code that does not work well when accelerated, due to some delayed
;    compile time evaluation.
; 3) Code that triggers an OPcache bug.
;
/home/learn4gd/public_html/geoip/v2/geoip2.phar




-------------------------------------

#Setup pool for additional domains by coopying other settings from the main one

#Copy from Email server

scp  ubuntu@10.10.10.5:/etc/php/7.4/fpm/pool.d/additional.conf /etc/php/7.4/fpm/pool.d/


vim /etc/php/7.4/fpm/pool.d/additional.conf

#Make folowing changes:

; pool name ('additional' here)
[additional]

pm = dynamic
listen = /run/php/php7.4-fpm-additional.sock
pm.max_children = 12
pm.start_servers = 2
pm.min_spare_servers = 1
pm.max_spare_servers = 3
pm.max_requests = 100

#/etc/php/7.4/fpm/php-fpm.conf at the bottom loads the pools and they have their own listening sockets.
To allow additional domains serve requests copy FilesMatch configuration from /etc/apache2/conf-available/php7.4-fpm.conf and paste into additional domains vhosts and  modify the listening socket

cat /etc/apache2/conf-available/php7.4-fpm.conf

vim /etc/apache2/conf-enabled/sites/additional-domains.conf


#Do separately additional-domains.conf , and powermedia-subdomains.conf as one contains 
#additional domains for Learn4good and the other is powermedia subdomains used for DEV purposes.
#Put the copied config into Vhost part


    <FilesMatch ".+\.ph(ar|p|tml)$">
        SetHandler "proxy:unix:/run/php/php7.4-fpm-additional.sock|fcgi://localhost"
    </FilesMatch>


#Do the same for Powermedia domain in:

vim /etc/apache2/sites-available/000-default.conf

   <FilesMatch ".+\.ph(ar|p|tml)$">
        SetHandler "proxy:unix:/run/php/php7.4-fpm-additional.sock|fcgi://localhost"
    </FilesMatch>


#Set Mod_deflate additional settings

sudo vim /etc/apache2/mods-enabled/deflate.conf

#Add inside If Module description


                DeflateCompressionLevel 4
                DeflateMemLevel 8



#Check if module is loaded mod_deflate is enabled with command:

apachectl -M| grep deflate

OR 

. /etc/apache2/envvars && apache2 -M | grep deflate

answer should be:  deflate_module (shared)


#Reload apache and FPM
# Make sure site cannot be opened by IP address with http and with https on all servers

systemctl restart php7.4-fpm
systemctl restart apache2


----------------------
MODULES Needed:

mod_asis
mod_deflate
mod_env
mod_expires
mod_fcgid
mod_headers 
mod_mime_magic
mod_mpm_event
mod_proxy
mod_proxy_fcgi
mod_proxy_http
mod_proxy_wstunnel
mod_remoteip
mod_slotmem_plain
mod_ssl 
mod_unique_id
mod_actions
mod_alias

----------------------------------------------------
PHP Extensions needed:

php74-libc-client
php74-pear
php74-php-bcmath
php74-php-bz2
php74-php-calendar
php74-php-cli
php74-php-common
php74-php-curl
php74-php-dba
php74-php-devel 
php74-php-exif 
php74-php-fileinfo
php74-php-fpm
php74-php-ftp
php74-php-gd
php74-php-gettext
php74-php-gmp
php74-php-iconv
php74-php-imap
php74-php-intl 
php74-php-mbstring
php74-php-memcached
php74-php-mysqlnd
php74-php-opcache
php74-php-pdo
php74-php-posix
php74-php-pspell
php74-php-soap
php74-php-sockets
php74-php-tidy
php74-php-xml
php74-php-xmlrpc
php74-php-zip

---------------------------------------------------

PECL modules:

swoole
imagick
memcached
msgpack (as is faster than igbinary)
timezonedb
mcrypt
ssdeep
Zip/Libzip
phpredis with lz4

---------------------------------------------------


Note:- When you are using PHP-FPM. All the PHP modules configurations are residing under /etc/php/7.4/fpm directory

phpenmod – Used to enable modules in PHP
phpdismod – Used to disable modules in PHP
phpquery – Used to view status of modules of PHP

### Syntax
phpenmod MODULE_NAME

### Enable mbstring php module
phpenmod mbstring

### Syntax for enabling specific version
phpenmod -v <PHP VERSION> <MODULE NAME>

### Enable module for specific php version
phpenmod -v 8.1 mbstring
phpenmod -v 7.4 mbstring

###Status of module by specifying SAPI name and version:

phpquery -v 7.4 -s cli -m curl
phpquery -v 7.4 -s fpm -m curl



--------------------------------------------


26) Copy the following files and folders to other servers after checking that all vhosts have AllowOverride None to disable Htaccess usage:

/etc/apache2/conf-enabled/dirs

/etc/apache2/sites-available/000-default.conf

/etc/apache2/apache2.conf

/etc/apache2/envvars

/var/log/apache2/fpm/

/etc/php/7.4/fpm/pool.d/

/etc/php/7.4/cli/php.ini

/etc/php/7.4/fpm/php.ini

/etc/apache2/conf-enabled/cf-list

/etc/php/7.4/mods-available/opcache.ini


systemctl restart php7.4-fpm
systemctl restart apache2

https://web1.learn4good.com:8443/fpm_statusas
https://web1.learn4good.com:8443/fpm_statusas?full
https://web1.learn4good.com:8443/ping


27) Test server after turning off Cloudflare proxying:

sudo apt install apache2-utils

ab -c 100 -n 1000 https://www.powermedia.lt/

ab -c 100 -n 1000 https://web1.learn4good.com:8443/ping



28) Imagemagick with Ghostscript:

PHP scripts should look for ImageMagick in /usr/bin and /usr/local/bin

GhostScript to support PDF files in ImageMagic needs to be installed:

sudo apt update
sudo apt install ghostscript
sudo apt install libgs-dev
sudo apt install libmagickcore-dev libmagickwand-dev
sudo apt install imagemagick


convert -list configure | grep bzlib

#Should give this list:
DELEGATES      bzlib djvu mpeg fftw fontconfig freetype jbig jng jpeg lcms lqr lzma openexr pango png ps tiff webp wmf x xml zlib
#gs in that line means Ghostscript is installed.

#This would create a logo in current folder:
convert logo: logo.gif

#This shows version:
convert --version

#Shows supported file types
identify -list format


#Install ImageMagick PECL extension

sudo pecl install imagick

vim /etc/php/7.4/mods-available/imagick.ini
#Add
extension=imagick.so

phpenmod imagick

Check if modules available number is equal to modules enabled

/etc/php/7.4/mods-available/ vs /etc/php/7.4/fpm/conf.d/

systemctl restart php7.4-fpm
systemctl restart apache2


29) #Check php info and delete the file afterwards:


echo "<?php phpinfo(); ?>" > /var/www/html/php_info.php

https://web1.learn4good.com:8443/php_info.php

rm /var/www/html/php_info.php



30) 
vim /etc/sysctl.conf


net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.all.secure_redirects = 0
net.ipv4.conf.all.send_redirects = 0
net.ipv4.tcp_max_orphans = 65536

#Forward is needed only on the server which has VPN setup

net.ipv4.ip_forward = 0
net.core.rmem_default = 65536
net.core.wmem_default = 65536
net.core.netdev_max_backlog = 1000
net.core.somaxconn = 65535
net.ipv4.tcp_max_syn_backlog = 30000
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_mem = 50576 64768 98152
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216
net.ipv4.tcp_fin_timeout = 10
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_slow_start_after_idle = 0
net.ipv4.tcp_keepalive_time = 60
net.ipv4.tcp_keepalive_intvl = 15
net.ipv4.tcp_keepalive_probes = 5
net.ipv4.tcp_max_tw_buckets = 2000000
net.ipv4.tcp_synack_retries = 1
net.ipv4.tcp_orphan_retries = 0
net.ipv4.tcp_syncookies = 0
net.ipv4.netfilter.ip_conntrack_max = 16777216
net.ipv4.tcp_timestamps = 1
net.ipv4.tcp_sack = 1
net.ipv4.tcp_congestion_control = htcp
net.ipv4.tcp_no_metrics_save = 1
net.ipv4.route.flush = 1
net.ipv4.conf.all.rp_filter = 1
net.ipv4.conf.lo.rp_filter = 1
net.ipv4.conf.eth0.rp_filter = 1
net.ipv4.conf.default.rp_filter = 1
net.ipv4.conf.all.accept_source_route = 0
net.ipv4.conf.lo.accept_source_route = 0
net.ipv4.conf.eth0.accept_source_route = 0
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.ip_local_port_range = 1024 65535
net.ipv4.tcp_window_scaling = 1
net.ipv4.tcp_rfc1337 = 1
net.ipv4.icmp_echo_ignore_broadcasts = 1
net.ipv4.icmp_ignore_bogus_error_responses = 1


vm.dirty_background_bytes=41943040


vm.dirty_ratio=40

vm.dirty_expire_centisecs=1000
vm.swappiness = 1
vm.overcommit_memory = 1
kernel.core_pattern = /var/crash/core.%e.%p.%h.%t
fs.inotify.max_user_watches=400000



#Run to apply changes:

sudo sysctl -p



31) #Install memcached

cd /opt
wget http://www.memcached.org/files/memcached-1.6.12.tar.gz
tar xvf memcached-1.6.12.tar.gz
cd memcached-1.6.12
./configure --with-libevent --enable-64bit
make -j20
make install


------------------------------------
#Startup options can be entered into systemd service command line systemd file should have these lines:

#Set startup options in service so that memcached will start up when the machine goes live. use -d from command line, ommit with systemd. Do not forget to use separate IP for each server

vim /usr/lib/systemd/system/memcached.service

======================
[Unit]
Description=Memcached
Before=httpd.service
After=network.target

[Service]
Type=simple
Restart=always
RestartSec=3
ExecStart=/usr/local/bin/memcached -u learn4gd -m 640 -l 10.10.10.1 -p 11211 -I 32M -o slab_reassign,slab_automove,lru_crawler,lru_maintainer,maxconns_fast,hash_algorithm=murmur3,modern

[Install]
WantedBy=multi-user.target

==========================

systemctl enable memcached.service
systemctl start memcached.service

----------------------


Settings:
vim /etc/php/7.4/mods-available/memcached.ini

; priority=25
extension=memcached.so
; You need to install php-igbinary package to use igbinary serializer
; and php-msgpack to use msgpack serializer
memcached.serializer=php



Status of memcached:

systemctl status memcached

#Choose all default answers but ANSWER yes to msgpack:
sudo pecl install memcached

vim /etc/php/7.4/mods-available/memcached.ini

#change default
memcached.serializer=php

#to
memcached.serializer=msgpack


#Enable memcached module
phpenmod memcached

systemctl restart apache2
systemctl restart php7.4-fpm

php --ini | grep memcached

#Check php info and delete the file afterwards:

echo "<?php phpinfo(); ?>" > /var/www/html/php_info.php

https://web1.learn4good.com:8443/php_info.php

rm /var/www/html/php_info.php

32) Install APCU

sudo pecl install apcu

APCU ini :

vim /etc/php/7.4/mods-available/apcu.ini


extension=apcu.so
#Enable/Disable
apc.enabled=1
# Memory Segments
apc.shm_size=512M
## PHP file cache 1 hour ##
apc.ttl=3600
## Garbage collection 1 hour ##
apc.gc_ttl=3600


#Enable module and restart Apache

phpenmod apcu


systemctl restart apache2
systemctl restart php7.4-fpm



echo "<?php phpinfo(); ?>" > /var/www/html/php_info.php

https://web1.learn4good.com:8443/php_info.php

rm /var/www/html/php_info.php

33) Install ssdeep

https://www.php.net/manual/en/ssdeep.installation.php

cd /opt
wget https://github.com/ssdeep-project/ssdeep/releases/download/release-2.14.1/ssdeep-2.14.1.tar.gz
tar zxf ssdeep-2.14.1.tar.gz
cd ssdeep-2.14.1/
./configure
make
make install
cp .libs/* /usr/lib


#Install PECL module
pecl install ssdeep


vim /etc/php/7.4/mods-available/ssdeep.ini

#Add

extension=ssdeep.so

phpenmod ssdeep

systemctl restart apache2
systemctl restart php7.4-fpm

echo "<?php phpinfo(); ?>" > /var/www/html/php_info.php

https://web1.learn4good.com:8443/php_info.php

rm /var/www/html/php_info.php


34) VPN - NOT DONE ON THIS SERVER YET, no need at the moment

sudo apt install wireguard wireguard-tools




35) Open Swoole installation:

The options passing in command line does not work currently, use manual answering for these options:

pecl install -D 'enable-sockets="no" enable-openssl="yes" enable-http2="yes" enable-mysqlnd="yes" enable-swoole-json="yes" enable-swoole-curl="yes" enable-cares="no"' openswoole


pecl install openswoole


#Add to PHP ini

vim /etc/php/7.4/mods-available/openswoole.ini

#Add

extension=openswoole.so


phpenmod openswoole



systemctl restart apache2
systemctl restart php7.4-fpm

echo "<?php phpinfo(); ?>" > /var/www/html/php_info.php

https://web1.learn4good.com:8443/php_info.php

rm /var/www/html/php_info.php


UPGRADING SWOOLE

pecl upgrade openswoole


36) Add php myadmin for MySQL administration (normally used just on Email server but if it is down - another one can be used)

cd /var/www/html
mkdir duombaze
chown learn4gd.learn4gd duombaze
cd duombaze
wget https://github.com/vrana/adminer/releases/download/v4.8.1/editor-4.8.1.php
wget https://github.com/vrana/adminer/releases/download/v4.8.1/adminer-4.8.1.php
wget https://raw.githubusercontent.com/vrana/adminer/master/plugins/dump-zip.php

#Create a file admineris.php and add code to support plugins, which includes original adminer.php
vim admineris.php
#Paste the code from adminer website plugins page and list plugin class names in it.

chown -R learn4gd.learn4gd duombaze

https://duombaze.powermedia.lt:8443/admineris.php


#PHP MyAdmin with authentication from https://www.adminer.org/en should have virtualhost on port 8443 and country limited

#Make subdomain serve on port 8443 and limit port access to RS,LT,IE,GB via iptables and in additional domains settings


#iptables rule for this port is already at the start of the iptables rules


https://duombaze.powermedia.lt/admineris.php

Requires basic auth and then DB login and IP




37) Email server setup - just on email server






38) in order to use mail command from shell such as (and also to send emails from other servers):

#echo "My message" | mail -s subject info@powermedia.lt
#or
#echo "tekstas" | mutt -s "subject" info@powermedia.lt


#Configure Mutt client not to save SENT file with a copy of sent messages by creating a file .muttrc in each user home directory:


vim /root/.muttrc


vim /home/learn4gd/.muttrc


vim /home/marko/.muttrc


vim /home/ubuntu/.muttrc

#And save the following in it:

set copy = no
set folder = ""



#DO NOT INSTALL THIS ON EMAIL SERVER!! It Will remove Postfix and SPF (this is needed just to send email from other servers)

#Need to install mailutils on other, non mail servers with nullmailer as relay SMTP server by specifying each server subdomain:

 sudo apt install nullmailer mailutils

#enter smarthost which is main email server local IP:

10.10.10.5 smtp

#To reconfigure use:

sudo dpkg-reconfigure nullmailer

# you can configure nullmailer by modifying the configuration files in /etc/nullmailer folder, in detail these are the files

adminaddr - contains the target email address to send emails

defaultdomain - marks the domain the emails are sent from

remotes - contains the email login configuration on the remote system

39) 
To allow WEB1 server to send its root emails to pastas@learn4good.com:

vim /etc/aliases


# Person who should get root's mail (this still does not allow receiving an email to root@learn4good.com as it needs to be added to vitual mailbox file)

# See man 5 aliases for format

root: pastas@learn4good.com



#Run the newaliases command, to compile aliases file. 

newaliases





40) Test mail sending from PHP on each server:

echo "<?php \$to = 'info@powermedia.lt';\$subject = 'Testing the subject';\$message = 'Hello text';\$headers = 'From: info@powermedia.lt' . \"\r\n\" .'Reply-To: info@powermedia.lt' . \"\r\n\" . 'X-Mailer: PHP/' . phpversion();mail(\$to, \$subject, \$message, \$headers);?>" > /var/www/html/mail.php

echo $`<?php $to = 'info@powermedia.lt';$subject = 'Testing the subject';$message = 'Hello text';$headers = 'From: info@powermedia.lt' . "\r\n" .'Reply-To: info@powermedia.lt' . "\r\n" . 'X-Mailer: PHP/' . phpversion();mail(\$to, $subject, $message, $headers);?> > /var/www/html/mail.php



#Open the page to see if mail is sent (one tests from command line another from PHP FPM):

php /var/www/html/mail.php

https://web1.learn4good.com:8443/mail.php

rm /var/www/html/mail.php


41) Setup Csync2:


sudo apt install -y gnutls-bin libgnutls28-dev librsync-dev bison flex inotify-tools

cd /opt
wget https://github.com/erlandl4g/csync2/archive/refs/heads/master.zip
unzip master.zip
mv csync2-master csync2

cd /opt/csync2

./autogen.sh clean
./autogen.sh
./configure --prefix=/usr --localstatedir=/var --sysconfdir=/etc/csync2/ --enable-sqlite3 --enable-systemd

make && make install


#Check libraries it is built with are showing up correctly:

ldd /usr/sbin/csync2



#Edit csync2 config file
vim /etc/csync2/csync2.cfg

nossl * *;
tempdir "/home/learn4gd/tmp";
group ht-cluster {
 host 10.10.10.1;
 host 10.10.10.3;
 host 10.10.10.5;
 host 10.10.10.7;
 host 10.10.10.9;
 key     /etc/csync2/ht-cluster.key;
 include /home/learn4gd/media_nfs;
 include /home/learn4gd/public_html/jobs/ml_models;
# exclude /home/learn4gd/media_nfs/private/jobs/cache;
# exclude /home/learn4gd/media_nfs/private/l4g_pages/cache;
# exclude /home/learn4gd/media_nfs/private/schools/cache;
 auto younger;

       action
       {
               pattern /home/learn4gd/public_html/jobs/ml_models/*;
               exec "/backup/scripts/swoole_reload.sh";
               do-local;
       }

}


#Add Port to Services list:

echo "csync2 30865/tcp" >> /etc/services


#Create cluster Key file and copy it to other peers

csync2 -k /etc/csync2/ht-cluster.key

#Copy all config, from EMAIL server

scp /etc/csync2/* root@10.10.10.1:/etc/csync2/


#If you get an error below - make sure the file does exist if it is in the config and that the config file and key file are identical:
#response from peer(/path/to/file): remote_host [15] <- Permission denied!
#Verify that the file mentioned is included in the remote host's /etc/csync2/csync2.cfg.

++++++++++++++++++++++++++++++++++++++++
#Clear old entries on config changes:
sudo csync2  -cIr
sudo csync2 -crvvv
sudo csync2 -R
#Force to win all conflicts
csync2 -fr /
++++++++++++++++++++++++++++++++++++++++

mkdir /backup/scripts
cd /backup/scripts
cp /opt/csync2/inotify_trigger_script/inotify_csync.sh /backup/scripts

#make sure  config path is correct and it should be /etc/csync2 on this configuration
vim /backup/scripts/inotify_csync.sh

vim /etc/systemd/system/csync2.service


[Unit]
Description=Csync2 Realtime sync Service
After=network.target

[Service]

User=root
Group=root

ExecStart=/backup/scripts/inotify_csync.sh -N 10.10.10.1

[Install]
WantedBy=default.target



systemctl daemon-reload
systemctl enable --now csync2.service
systemctl start csync2.service


42) Install Manticore

#We use Development package by default (second option), but we install it only as needed, not on every release

#Install the official Manticore Search APT repository for Ubuntu

#cd /opt
#wget https://repo.manticoresearch.com/manticore-repo.noarch.deb
#dpkg -i manticore-repo.noarch.deb
#apt update

#apt install manticore manticore-columnar-lib manticore-dbgsym


#To install Development package:

cd /opt
wget https://repo.manticoresearch.com/manticore-dev-repo.noarch.deb
sudo dpkg -i manticore-dev-repo.noarch.deb
sudo apt update
sudo apt install manticore manticore-columnar-lib manticore-dbgsym


#Copy stopwords and other txt files from /etc/manticoresearchd folder

#Edit configuration file for each. We run RT indexes for all. Each has individual settings

vim /etc/manticoresearch/manticore.conf




#############################################################################
## common settings
#############################################################################

common
{
  lemmatizer_base = /etc/manticoresearch/dict/
  plugin_dir      = /usr/local/lib/manticore

}

#############################################################################
## searchd settings
#############################################################################
 #Sometimes need to inspect slow queries by enabling log
 #log = /var/log/manticore/searchd.log
 #query_log = /var/log/manticore/query.log
 #pid_file = /var/run/manticore/searchd.pid
 #data_dir is used ONLY IN RT_MODE
 #data_dir = /var/lib/manticore/data
 #query_log_format = sphinxql
#What you need to know:
#- RT index is very similar to a distributed index of multiple local indexes. The local indexes are called "disk chunks"
#- rt_mem_limit limits size of the RAM chunk
#- RAM chunk does merging after each Insert or Delete, that's why it's more beneficial to do batch INSERTs
#- merging larger segments take longer, that's why it may be suboptimal to have too large RAM chunk (and therefore rt_mem_limit)
#- pseudo_sharding works on plain and RT indexes. RT index after some time gets
#- to the state when it has multiple disk chunks which by default is limited by # of CPU cores * 2. But this introduces overhead compared to pseaudo sharding.
#- This is how manual OPTIMIZE works (leaves cpu cores * 2 disk chunks). Auto optimize is enabled by default and works the same way by default.
#- searchd flushes RAM chunk to disk on shutdown and periodically. Flushing tens of gigabytes may be slow.
# the rule of thumb with rt_mem_limit if you more or less know the final size of the index is rt_mem_limit = ~ final size / CPU_cores


searchd
{

  listen = 127.0.0.1:9312
  listen = 10.10.10.1:9312
  listen = 127.0.0.1:9306:mysql
  listen = 10.10.10.1:9306:mysql
  listen = 127.0.0.1:9318:mysql_vip
  listen = 10.10.10.1:9315-9325:replication

 server_id        = 1
 auto_optimize    = 1
 optimize_cutoff  = 13
 max_open_files   = max
 network_timeout  = 5
 client_timeout   = 300
 #threads          = 64 #allow daemon to auto-configure that option,  it should be set to CPU count
 max_threads_per_query = 32
 pseudo_sharding  = 1
 net_workers      = 1
 read_buffer_docs = 256K
 read_buffer_hits = 256K
 seamless_rotate  = 1
 preopen_indexes  = 1
 unlink_old       = 1
 shutdown_timeout = 1m
 max_packet_size  = 128M #Some jobs have large job descriptions reaching 65Kb - and insert of 10000 jobs can be a large packet
 max_filters      = 256
 max_filter_values= 4096
 expansion_limit  = 10
 rt_flush_period  = 1800
 #Comment out time to Log all queries
 query_log_min_msec= 60
 data_dir         = /var/lib/manticore/data
 pid_file         = /var/run/manticore/searchd.pid
 log              = /var/log/manticore/searchd.log
 binlog_path      = /var/lib/manticore/data
 query_log        = /var/log/manticore/query.log
 query_log_format = sphinxql
 #query_log_commands = 1



}

# --eof--



#Edit the default systemd file after installation:

vim /usr/lib/systemd/system-generators/manticore-generator

#See if need to add this:

LimitMEMLOCK=infinity



#Add user Manticore to the group root to allow reading config files if they are edited/created by root

usermod -a -G root manticore
groups manticore

#Enable Manticore
systemctl daemon-reload
systemctl enable manticore
systemctl start manticore


#Log rotate must be under  manticore user

vim /etc/logrotate.d/manticore


/var/log/manticore/*.log {
        su manticore manticore
        rotate 10
        nocompress
        size 15M
        create 0666 manticore manticore
        notifempty
        nomissingok
        sharedscripts
        postrotate
                mysql -P9306 -h0 -e 'FLUSH LOGS;'
        endscript
        su root root




#If needed - Change logs and data folder owner to manticore when searchd is STOPPED

chown manticore.manticore /var/log/manticore

chown -R manticore.manticore /var/log/manticore/*

chown manticore.manticore /var/lib/manticore

find /var/lib/manticore -type d -exec chmod 755 {} \;

find /var/lib/manticore -type f -exec chmod 644 {} \;
find /var/log/manticore -type f -exec chmod 644 {} \;

chown -R manticore.manticore /var/lib/manticore/*

chown -R manticore.manticore /etc/manticoresearch/*


#Set environment variables to dump core on crash and to log replication, to preread indexes before start

systemctl set-environment _ADDITIONAL_SEARCHD_PARAMS='--coredump --logreplication --force-preread'

systemctl restart manticore


43) Enter new server IPs on Google API Credentials

https://console.cloud.google.com/apis/dashboard?orgonly=true&project=oceanic-catcher-289318&supportedpurview=organizationId


APIs and Services->

Credentials

https://console.cloud.google.com/apis/credentials?orgonly=true&project=oceanic-catcher-289318&supportedpurview=organizationId


API key restrictions by IP


https://console.cloud.google.com/apis/credentials/key/e694bd45-f5bf-458f-a529-76e6b41e2d24?orgonly=true&project=oceanic-catcher-289318&supportedpurview=organizationId


44) PTR record should show hostname - must point DNS to its IP address during PTR record change in control panel network interfaces


45) Adjust logrotate start on each server at different times by setting different minute start:

vim /etc/crontab

46) Check that remote IP module is installed to capture IP from classic load balancer:

sudo apachectl -t -D DUMP_MODULES | grep -i remoteip


47) Apache error log
[Sat Jan 15 00:04:54.052713 2022] [ssl:warn] [pid 370413:tid 139849421035264] (22)Invalid argument: AH02027: Failed to release SSL session cache lock


This happens when the APACHE_RUN_USER is used for SSH login purposes too. Then, systemd clears all the locks of the user during logout, including the locks used by Apache 2.

The solution is to prevent systemd from removing the locks by adding the following line to /etc/systemd/logind.conf:

RemoveIPC=no

Which is not great solution and best to not log in with learn4gd user if possible or very seldom.

Another AND MAIN PROBLEM is Apache2 SSL cache folder being owned by www-data user which is default user during installation and since we run Apache 2 under learn4gd - it may have problem storing anything in /var/cache/apache2/mod_cache_disk folder. For this reason we have to change owner and search through the system for remaining files/folders owned by www-data user.


Search:

find . -user www-data

Shows that there are folders owned by this user in:

/var/cache/apache2/mod_cache_disk
/var/lib/apache2/fcgid
/var/lib/apache2/fcgid/sock
/run/php

We change ownership of these folders to learn4gd (not sure how web pages were served until now but they were working somehow but also sometimes were giving SSL cache error which is less important than PHP 


chown learn4gd.learn4gd /var/cache/apache2/mod_cache_disk
chown learn4gd.learn4gd /var/lib/apache2/fcgid
chown learn4gd.learn4gd /var/lib/apache2/fcgid/sock
chown learn4gd.learn4gd /run/php

systemctl restart php7.4-fpm
systemctl restart apache2

48) Create file and cronjob to do firewall country ip update once a month on each server:

32 4 10 * * /backup/scripts/renew_firewall_IP_country.sh



cd /usr/share/xt_geoip
rm dbip-country-lite.csv
/usr/lib/xtables-addons/xt_geoip_dl
#A space is needed before * as it reads whole directory that way
/usr/lib/xtables-addons/xt_geoip_build -D /usr/share/xt_geoip *.csv
hostas=hostname
echo "Firewall Geoip database updated in /usr/share/xt_geoip" | mail -s $hostas" updated FW Geoip" pastas@learn4good.com


49) To allow seeing Apache status and run daemon check script need to allow its access on localhost IP. A browser is also needed:

apt install lynx

#Edit main site config:

vim /etc/apache2/sites-available/000-default.conf

#Above redirection on port 80 - add this:


<VirtualHost 127.0.0.1:80>
    #In order to allow Apache status monitoring
</VirtualHost>

<VirtualHost *:80>
        RewriteEngine on
        RewriteRule ^/?(.*)$ https://%{HTTP_HOST}/$1 [R=301,L]
</VirtualHost>


#Restart Apache

systemctl restart apache2

#Check apache status:

apachectl fullstatus

50) Copy shell scripts (all) into /backup/scripts folder, modify their IPs, disable running on those which are not needed, add the needed ones to crontab

Add Crons to servers:

33 4 * * 6 /backup/scripts/renew_firewall_IP_country.sh
*/5 * * * * /backup/scripts/check_mariadb_replication.sh
*/3 * * * * /backup/scripts/daemon_check.sh
05 22 * * * /backup/scripts/mk_backup > /dev/null


51) Create service for PHP FPM monitoring to run:

vim /etc/systemd/system/php-fpm-emergency.service

[Unit]
Description=PHP FPM Emergency restart Service
After=network.target

[Service]

User=root
Group=root

ExecStart=/backup/scripts/php_fpm_emergency_restart.sh

[Install]
WantedBy=default.target



systemctl enable php-fpm-emergency
systemctl start php-fpm-emergency

52) Make git access via 8444 port separate from the rest and add separate country rule on it. This will allow blocking  GIT access by country separate from Database adminer and Apache Status page. Apache config on all servers for simplicity, but Firewall rule just on web1 as GIT commits should be going just to web1 server

#ONLY ON WEB1
iptables -A INPUT -m geoip --src-cc RS,LT,GB,IE,RU -p TCP --dport 8444 -j ACCEPT

vim /etc/apache2/apache2.conf

#Additional port for listening for GIT commits

<IfModule ssl_module>
        Listen 8444
</IfModule>

<IfModule mod_gnutls.c>
        Listen 8444
</IfModule>



53) Install Git, see Git Instalation for Ubuntu File

a2enmod env cgid alias rewrite
systemctl restart apache2

#Continue on Git installation file

#Do not  forget changing hostname in pull.exp and in git /config files as during move it was changed to:

[remote "origin"]
        url = https://cweb1.learn4good.com/kruovykla/


54) Swoole tasks queue and other crons for jobsite monitored by supervisor:

apt update
apt install supervisor


chmod 777 /var/log/supervisor

#You may need to add inet server lines to have Web interface:


vim /etc/supervisor/supervisord.conf

; supervisor config file

[unix_http_server]
file=/var/run/supervisor.sock   ; (the path to the socket file)
chmod=0700                       ; sockef file mode (default 0700)

[supervisord]
logfile=/var/log/supervisor/supervisord.log ; (main log file;default $CWD/supervisord.log)
pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid)
childlogdir=/var/log/supervisor            ; ('AUTO' child log dir, default $TEMP)

; the below section must remain in the config file for RPC
; (supervisorctl/web interface) to work, additional interfaces may be
; added by defining them in separate rpcinterface: sections
[rpcinterface:supervisor]
supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface

[inet_http_server]
port=*:9001
username=priziuretojas
password=supervaizeris

[supervisorctl]
serverurl=unix:///var/run/supervisor.sock ; use a unix:// URL  for a unix socket

; The [include] section can just contain the "files" setting.  This
; setting can list multiple files (separated by whitespace or
; newlines).  It can also contain wildcards.  The filenames are
; interpreted as relative to this file.  Included files *cannot*
; include files themselves.

[include]
files = /etc/supervisor/conf.d/*.conf



systemctl restart supervisor
systemctl status supervisor


#Open a port for supervisor web interface access - Which is still not very safe, and should be limited to access via local IP, which is accessed via VPN only
#Delete this rule later after testing and viewing it via VPN on local IP

iptables -A INPUT -m geoip --src-cc RS,LT,GB -p TCP --dport 9001 -j ACCEPT

sudo netfilter-persistent save

sudo netfilter-persistent reload

#Check supervisor web interface:

http://135.148.35.73:9001/
http://10.10.10.7:9001/

#Adding  programs for Supervisor to monitor:


vim /etc/supervisor/conf.d/queue_worker_cron.conf

[program:Queue_worker_cron_job]
command=/usr/bin/php /home/learn4gd/public_html/jobs/index.php controller=cron action=execute id=64
autostart=true
autorestart=true
startsecs=0
startretries=30
user=learn4gd
redirect_stderr=true
stdout_logfile=/home/learn4gd/public_html/jobs/tmp/logs/db-queue-worker.log


vim /etc/supervisor/conf.d/nfs_availability_cron.conf

;;[program:NFS_availability_cron_job]
;;command=/usr/bin/php /home/learn4gd/public_html/jobs/index.php controller=cron action=execute id=61             ; the program (relative uses PATH, can take args)
;process_name=%(program_name)s ; process_name expr (default %(program_name)s)
;numprocs=1                    ; number of processes copies to start (def 1)
;directory=/tmp                ; directory to cwd to before exec (def no cwd)
;umask=022                     ; umask for process (default None)
;priority=999                  ; the relative start priority (default 999)
;;autostart=true                ; start at supervisord start (default: true)
;;autorestart=true              ; retstart at unexpected quit (default: true)
;;startsecs=0                  ; number of secs prog must stay running (def. 1), 0 means that it can run very briefly
;;startretries=30                ; max # of serial start failures (default 3)
;exitcodes=0,2                 ; 'expected' exit codes for process (default 0,2)
;stopsignal=QUIT               ; signal used to kill process (default TERM)
;stopwaitsecs=10               ; max num secs to wait b4 SIGKILL (default 10)
;;user=learn4gd                   ; setuid to this UNIX account to run the program
;;redirect_stderr=true          ; redirect proc stderr to stdout (default false)
;;stdout_logfile=/home/learn4gd/public_html/jobs/tmp/logs/nfs-availability-cron.log        ; stdout log path, NONE for none; default AUTO
;stdout_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB)
;stdout_logfile_backups=10     ; # of stdout logfile backups (default 10)
;stdout_capture_maxbytes=1MB   ; number of bytes in 'capturemode' (default 0)
;stdout_events_enabled=false   ; emit events on stdout writes (default false)
;stderr_logfile=/home/learn4gd/public_html/jobs/tmp/logs/nfs-availability-cron-error.log        ; stderr log path, NONE for none; default AUTO
;stderr_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB)
;stderr_logfile_backups=10     ; # of stderr logfile backups (default 10)
;stderr_capture_maxbytes=1MB   ; number of bytes in 'capturemode' (default 0)
;stderr_events_enabled=false   ; emit events on stderr writes (default false)
;environment=A=1,B=2           ; process environment additions (def no adds)
;serverurl=AUTO                ; override serverurl computation (childutils)



vim /etc/supervisor/conf.d/bugtracker_rt_index_cron.conf


[program:Bugtracker_RT_index_cron_job]
command=/usr/bin/php /home/learn4gd/public_html/reqtrack/index.php controller=cron action=execute id=2
autostart=true
autorestart=true
startsecs=0
startretries=30
user=learn4gd
redirect_stderr=true
stdout_logfile=/home/learn4gd/public_html/reqtrack/tmp/logs/rt-index-cron.log


----------------------------------------------------
#We need to run the below commands to let the supervisor to reread the configuration file and apply the latest changes.

supervisorctl reread
supervisorctl update


#To run the supervisor client , Run

supervisorctl


#To check the status of the process , Run

status

#We can manage each programs by running "command programname":

tail Bugtracker_RT_index_cron_job stderr


#We can also check the status of the programs from the linux bash by running,

supervisorctl status
------------------------------------------------------

55)  See Ubuntu Redis and Sentinels configuration.txt for configuring Redis and its Sentinels for each server

56)  add crontabs for root,learn4gd users , keep learn4gd user crons disabled as site is not functioning yet on each server

57) Copy Rotate log files settings - Manticore, Redis, supervisor, xml-times, tmp-logs

cd /etc/logrotate.d

58) Enable Perl and CGI handling on frontend:


apt install perl

a2enmod cgid

a2enconf serve-cgi-bin

#Edit config for cgi and perl file handling
#Save this as commented out in

vim /etc/apache2/conf-available/serve-cgi-bin.conf

#And paste under VHOST with 8443 post handling web1 host (as other hosts basically do not need CGI handling
#This allows only such : https://web1.learn4good.com:8443/cgi-bin/kopijuok.pl

vim /etc/apache2/conf-enabled/sites/l4g-subdomains.conf


<IfModule mod_alias.c>
        <IfModule mod_cgi.c>
                Define ENABLE_USR_LIB_CGI_BIN
        </IfModule>

        <IfModule mod_cgid.c>
                Define ENABLE_USR_LIB_CGI_BIN
        </IfModule>

        <IfDefine ENABLE_USR_LIB_CGI_BIN>
                ScriptAlias /cgi-bin/ /var/www/html/cgi-bin/
                <Directory "/var/www/html/cgi-bin">
                        AllowOverride None
                        Options +ExecCGI -MultiViews +SymLinksIfOwnerMatch -Indexes
                            AddHandler cgi-script .cgi .pl .py .rb
                             Require all granted
                </Directory>
        </IfDefine>
</IfModule>

systemctl restart apache2

59) Copy kopijuok.pl, slow.pl and logrotate.pl to /var/www/html/cgi-bin

#Make sure ExecCGI option  is in place in config file and perl file output begins with
#print "Content-Type: text/plain\n\n"; to prevent script "download" instead of loading into browser.

#Make sure learn4gd user is in sudeoers and is allowed to execute the shell scripts Perl is executing

#sync_content.sh script should be executable in /backup/scripts as well

#Test copying with 
https://web1.learn4good.com:8443/cgi-bin/kopijuok.pl


60) From old servers hosts file remove domain mapping to the IP, so web1.learn4good.com record is not present anymore, which confuses old server

vim /etc/hosts


61) Copy /home/learn4gd ,service_check, common, server_id folders


Sync content from old to new servers (pull to web1 and from it - copy to other new servers):

Execute from new Server - web1:
rsync --timeout=20 --del --specials -aHlogtpEW root@67.227.189.210:/home/learn4gd/media_nfs/ /home/learn4gd/media_nfs/
rsync --timeout=20 --del --specials -aHlogtpEW --exclude 'media' --exclude 'media_nfs' root@67.227.189.210:/home/learn4gd/public_html/ /home/learn4gd/public_html/
rsync --timeout=20 --del --specials -aHlogtpEW root@67.227.189.210:/home/learn4gd/service_check/ /home/learn4gd/service_check/
rsync --timeout=20 --del --specials -aHlogtpEW root@67.227.189.210:/home/learn4gd/server_id/ /home/learn4gd/server_id/
rsync --timeout=20 --del --specials -aHlogtpEW root@67.227.189.210:/home/learn4gd/common/ /home/learn4gd/common/

Delete in public_html:

.well-known folders everywhere
.ftpquota files everywhere
.htaccess files everywhere
.opcache
aquota.user
cgi-bin
lost+found

biz
couk
eu
ie
l4gcouk
l4ginfo
l4gnet
l4gorg
learning4good
net
org
us



Create Symlinks to NFS media folder:

ln -s /home/learn4gd/media_nfs /home/learn4gd/public_html/media_nfs

ln -s /home/learn4gd/media_nfs /home/learn4gd/public_html/media

chown -h learn4gd.learn4gd media_nfs

chown -h learn4gd.learn4gd media


Review how additional domains access schools pages and delete their folders in public_html as vhost is pointing at schools, see the index php files in those folders first

Delete cgi-bin folder in public_html

Check file ownership - all should be learn4gd, maybe do chown for all:

chown -R learn4gd.learn4gd /home/learn4gd/public_html/
chown -R learn4gd.learn4gd /home/learn4gd/common/

Sync all the above folders to all other 4 servers, they only take from web1 (or better use sync script to check PERL script is working from web)


rsync --timeout=20 --del --specials -aHlogtpEW --exclude 'media' --exclude 'media_nfs' root@10.10.10.1:/home/learn4gd/public_html/ /home/learn4gd/public_html/

rsync --timeout=20 --del --specials -aHlogtpEW root@10.10.10.1:/home/learn4gd/common/ /home/learn4gd/common/

rsync --timeout=20 --del --specials -aHlogtpEW root@10.10.10.1:/home/learn4gd/service_check/ /home/learn4gd/service_check/



rsync --timeout=20 --del --specials -aHlogtpEW root@10.10.10.1:/home/learn4gd/server_id/ /home/learn4gd/server_id/
#After this - enter server ID number for each server:

vim /home/learn4gd/server_id/server.txt

62) Return to GIT setup file and create all repositories on web1 and make them bare repositories, then on all servers create each repository for each project

63) Make /var/www/html to not keep cache as otherwise browser returns same content on git commits or database browsing by adding this to dir folder root file:

<Directory "/var/www/html">
    Options +Includes -Indexes +FollowSymLinks
    AllowOverride None
    Require all granted
    Header set Cache-Control "no-cache, no-store, must-revalidate"
    Header set Pragma "no-cache"
    Header set Expires 0
</Directory>

64) Route all commits to new GIT server 

#Disable old Git Access on old Web1 server Apache config
#disable git htpasswd file on old server

#Change GIT config files on old servers to pull data from the new server
#Old server IPs should be on firewall already and should be allowed to make a pull as port 8444 for git is country limited

#Review Htpasswd file for GIT, For /var/www/html , Inform everyone about new URL change

65) Finish Git setup by including all repositories and fully setting up website. No more commits to the old server should be done.

#Do not forget to set back to web1 hostname in both places:

# in pull.exp and in git /config files for each repository on web1, then make them copied to other servers using GIT copying script as during move it was changed to:

[remote "origin"]
        url = https://cweb1.learn4good.com/kruovykla/


66) Upload latest manticore RT index config, check that each server has unique server_id in its config, create one test index, enable replication, check how it is replicated, if there are any errors in the logs

Test cluster working cluster, remove test index once finished


67) Update backupai.sh script to make full independent backup of each server ETC folder, database backups, and shell scripts in backup folder

68) Cleanup programs and install composer

apt autoremove
apt update

cd /opt
php -r "copy('https://getcomposer.org/installer', 'composer-setup.php');"
php composer-setup.php
php -r "unlink('composer-setup.php');"
sudo mv composer.phar /usr/bin/composer

